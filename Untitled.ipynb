{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b4a1d5-4093-4401-ad74-44d3cf7a63f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7010f5c3-01b4-43d1-b167-a450de19aa09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e4eddd21-15d3-4c87-bad5-c4d46b1ca58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from ultralytics import YOLO\n",
    "from ultralyticsplus import YOLO, render_result\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eef09f-1fc9-4c44-b983-6edf8c847075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "84795458-7694-4305-8a7b-73003105bbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table(image_path):\n",
    "\n",
    "    # load model\n",
    "    model = YOLO('foduucom/table-detection-and-extraction')\n",
    "\n",
    "    # set model parameters\n",
    "    model.overrides['conf'] = 0.25  # NMS confidence threshold\n",
    "    model.overrides['iou'] = 0.45  # NMS IoU threshold\n",
    "    model.overrides['agnostic_nms'] = False  # NMS class-agnostic\n",
    "    model.overrides['max_det'] = 1000  # maximum number of detections per image\n",
    "\n",
    "    # perform inference\n",
    "    results = model.predict(image_path)\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # table_coords = results[0].boxes\n",
    "    table_coords = results[0].boxes.xyxy.numpy()  # Convert boxes to NumPy array\n",
    "\n",
    "    x1, y1, x2, y2 = map(int, list(table_coords)[0][:4])\n",
    "\n",
    "    # Crop table region\n",
    "    table_img = image[y1:y2, x1:x2]\n",
    "\n",
    "    # Extract text from cropped table using Tesseract OCR\n",
    "    table_text = pytesseract.image_to_string(table_img)\n",
    "\n",
    "    print (\"--- table_text ---\")\n",
    "    print (table_text)\n",
    "    print (\"--- table_text ---\")\n",
    "\n",
    "    # Parse OCR output into structured JSON\n",
    "    rows = table_text.strip().split(\"\\n\")\n",
    "    headers = rows[0].split(\"\\t\")\n",
    "    table_data = [\n",
    "        dict(zip(headers, row.split(\"\\t\"))) for row in rows[1:] if row.strip()\n",
    "    ]\n",
    "\n",
    "    print (\"--- table_data ---\")\n",
    "    print (table_data)\n",
    "    return table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f11aeb29-9454-4054-af99-69eeeb639f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.43 ðŸš€ Python-3.11.11 torch-2.5.1+cu124 CPU\n",
      "Model summary (fused): 168 layers, 11126358 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\n",
      "image 1/1 /home/ahsan/Downloads/table1.png: 128x640 1 bordered, 87.7ms\n",
      "Speed: 0.3ms preprocess, 87.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- table_text ---\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Plastic Acetone Flame test Heat Crease color\n",
      "1 No effect Green color _| Softens None\n",
      "\n",
      "2 Sofiened â€˜No change No change White\n",
      "\n",
      "3 No effect Red color Softens â€˜None\n",
      "\n",
      "4 No effect. Green color Softens none\n",
      "\n",
      " \n",
      "\f",
      "\n",
      "--- table_text ---\n",
      "--- table_data ---\n",
      "[{'Plastic Acetone Flame test Heat Crease color': '1 No effect Green color _| Softens None'}, {'Plastic Acetone Flame test Heat Crease color': '2 Sofiened â€˜No change No change White'}, {'Plastic Acetone Flame test Heat Crease color': '3 No effect Red color Softens â€˜None'}, {'Plastic Acetone Flame test Heat Crease color': '4 No effect. Green color Softens none'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Plastic Acetone Flame test Heat Crease color': '1 No effect Green color _| Softens None'},\n",
       " {'Plastic Acetone Flame test Heat Crease color': '2 Sofiened â€˜No change No change White'},\n",
       " {'Plastic Acetone Flame test Heat Crease color': '3 No effect Red color Softens â€˜None'},\n",
       " {'Plastic Acetone Flame test Heat Crease color': '4 No effect. Green color Softens none'}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the table image\n",
    "image_path = \"/home/ahsan/Downloads/table1.png\"\n",
    "\n",
    "# Extract and print the table data\n",
    "table_data = extract_table(image_path)\n",
    "table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e45f1ca-af9a-40ea-8742-1c1ece85fdec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b0cfd5-a3b4-4875-9603-3c5f4aeba542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6839a5-586b-43fb-b513-f31a3e72454f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab2ae5c-9553-4022-93d7-a625f4f140e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a840ddbe-5f86-4cf8-8553-ec324487c968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aef200-32c7-47f7-a523-ac9174496928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4604a8a5-25be-4d34-9864-a14bd66d269a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.43 ðŸš€ Python-3.11.11 torch-2.5.1+cu124 CPU\n",
      "Model summary (fused): 168 layers, 11126358 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\n",
      "image 1/1 /home/ahsan/Downloads/table.png: 288x640 1 bordered, 135.0ms\n",
      "Speed: 0.7ms preprocess, 135.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "/tmp/ipykernel_16095/3939436828.py:26: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load model\n",
    "model = YOLO('foduucom/table-detection-and-extraction')\n",
    "\n",
    "# set model parameters\n",
    "model.overrides['conf'] = 0.25  # NMS confidence threshold\n",
    "model.overrides['iou'] = 0.45  # NMS IoU threshold\n",
    "model.overrides['agnostic_nms'] = False  # NMS class-agnostic\n",
    "model.overrides['max_det'] = 1000  # maximum number of detections per image\n",
    "\n",
    "image_path = \"/home/ahsan/Downloads/table.png\"\n",
    "\n",
    "# perform inference\n",
    "results = model.predict(image_path)\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# table_coords = results[0].boxes\n",
    "table_coords = results[0].boxes.xyxy.numpy()  # Convert boxes to NumPy array\n",
    "\n",
    "x1, y1, x2, y2 = map(int, list(table_coords)[0][:4])\n",
    "\n",
    "# Crop table region\n",
    "table_img = image[y1:y2, x1:x2]\n",
    "\n",
    "plt.imshow(table_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7fe2c1-b4d5-412d-9a52-84f0ba880d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1dc57c4-ab1a-4481-85b7-bc2e13614e2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting easyocr\n",
      "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from easyocr) (2.5.1)\n",
      "Requirement already satisfied: torchvision>=0.5 in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from easyocr) (0.20.1)\n",
      "Collecting opencv-python-headless (from easyocr)\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scipy in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from easyocr) (1.14.1)\n",
      "Requirement already satisfied: numpy in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from easyocr) (1.26.4)\n",
      "Requirement already satisfied: Pillow in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from easyocr) (11.0.0)\n",
      "Collecting scikit-image (from easyocr)\n",
      "  Downloading scikit_image-0.25.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting python-bidi (from easyocr)\n",
      "  Downloading python_bidi-0.6.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: PyYAML in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from easyocr) (6.0.2)\n",
      "Requirement already satisfied: Shapely in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from easyocr) (2.0.6)\n",
      "Collecting pyclipper (from easyocr)\n",
      "  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting ninja (from easyocr)\n",
      "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: filelock in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from torch->easyocr) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from torch->easyocr) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from torch->easyocr) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from torch->easyocr) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from torch->easyocr) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from torch->easyocr) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from torch->easyocr) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from torch->easyocr) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from torch->easyocr) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from torch->easyocr) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from torch->easyocr) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from torch->easyocr) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from torch->easyocr) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from torch->easyocr) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from torch->easyocr) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from torch->easyocr) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from torch->easyocr) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from torch->easyocr) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from torch->easyocr) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from sympy==1.13.1->torch->easyocr) (1.3.0)\n",
      "Collecting imageio!=2.35.0,>=2.33 (from scikit-image->easyocr)\n",
      "  Downloading imageio-2.36.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->easyocr)\n",
      "  Downloading tifffile-2024.12.12-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: packaging>=21 in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from scikit-image->easyocr) (24.2)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image->easyocr)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ahsan/anaconda3/envs/tableExt/lib/python3.11/site-packages (from jinja2->torch->easyocr) (3.0.2)\n",
      "Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
      "Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Downloading python_bidi-0.6.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (286 kB)\n",
      "Downloading scikit_image-0.25.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "Downloading imageio-2.36.1-py3-none-any.whl (315 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading tifffile-2024.12.12-py3-none-any.whl (227 kB)\n",
      "Installing collected packages: python-bidi, pyclipper, tifffile, opencv-python-headless, ninja, lazy-loader, imageio, scikit-image, easyocr\n",
      "Successfully installed easyocr-1.7.2 imageio-2.36.1 lazy-loader-0.4 ninja-1.11.1.3 opencv-python-headless-4.10.0.84 pyclipper-1.3.0.post6 python-bidi-0.6.3 scikit-image-0.25.0 tifffile-2024.12.12\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0d0cd142-155c-4cbe-828a-6b8415392fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e432795-f52d-4765-835c-2d9a94ef3b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of detected contours (rows): 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Plastic': '1',\n",
       "  'Acetone': 'No effect',\n",
       "  'Flame test': 'Green color',\n",
       "  'Heat': 'Softens',\n",
       "  'Crease color': 'None'},\n",
       " {'Plastic': '2',\n",
       "  'Acetone': 'Softened',\n",
       "  'Flame test': 'No change',\n",
       "  'Heat': 'No change',\n",
       "  'Crease color': 'White'},\n",
       " {'Plastic': '3',\n",
       "  'Acetone': 'No effect',\n",
       "  'Flame test': 'Red color',\n",
       "  'Heat': 'Softens',\n",
       "  'Crease color': 'None'},\n",
       " {'Plastic': '4',\n",
       "  'Acetone': 'No effect',\n",
       "  'Flame test': 'Green color',\n",
       "  'Heat': 'Softens',\n",
       "  'Crease color': 'none'}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the table image\n",
    "image_path = \"/home/ahsan/Downloads/table1.png\"\n",
    "\n",
    "# Extract and print the table data\n",
    "table_data = extract_table_easyocr(image_path)\n",
    "table_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e26bdfd-92d0-47b1-afa3-80c3823b7a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b248d5-d583-46cb-bfc2-23ae2d15e83e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f61d8f7-2d51-44dd-bd60-da25a4f4e04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "# from google.colab.patches import cv2_imshow\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import easyocr\n",
    "reader = easyocr.Reader(['th','en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fdb0c1a-965a-442c-b6f4-69c03f6274cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def table_detection(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    (thresh, img_bin) = cv2.threshold(img_gray, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    img_bin = cv2.bitwise_not(img_bin)\n",
    "\n",
    "    kernel_length_v = (np.array(img_gray).shape[1])//120\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length_v))\n",
    "    im_temp1 = cv2.erode(img_bin, vertical_kernel, iterations=3)\n",
    "    vertical_lines_img = cv2.dilate(im_temp1, vertical_kernel, iterations=3)\n",
    "\n",
    "    kernel_length_h = (np.array(img_gray).shape[1])//40\n",
    "    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length_h, 1))\n",
    "    im_temp2 = cv2.erode(img_bin, horizontal_kernel, iterations=3)\n",
    "    horizontal_lines_img = cv2.dilate(im_temp2, horizontal_kernel, iterations=3)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    table_segment = cv2.addWeighted(vertical_lines_img, 0.5, horizontal_lines_img, 0.5, 0.0)\n",
    "    table_segment = cv2.erode(cv2.bitwise_not(table_segment), kernel, iterations=2)\n",
    "    thresh, table_segment = cv2.threshold(table_segment, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(table_segment, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    count = 0\n",
    "\n",
    "    full_list=[]\n",
    "    row=[]\n",
    "    data=[]\n",
    "    first_iter=0\n",
    "    firsty=-1\n",
    "\n",
    "\n",
    "    for c in contours:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "\n",
    "        if  h > 9 and h<100:\n",
    "            if first_iter==0:\n",
    "              first_iter=1\n",
    "              firsty=y\n",
    "            if firsty!=y:\n",
    "              row.reverse()\n",
    "              full_list.append(row)\n",
    "              row=[]\n",
    "              data=[]\n",
    "            # print(x,y,w,h)\n",
    "            cropped = img[y:y + h, x:x + w]\n",
    "            # cv2_imshow(cropped)\n",
    "            bounds = reader.readtext(cropped)\n",
    "\n",
    "            try:\n",
    "              data.append(bounds[0][1])\n",
    "              data.append(w)\n",
    "              row.append(data)\n",
    "              data=[]\n",
    "            except:\n",
    "              data.append(\"--\")\n",
    "              data.append(w)\n",
    "              row.append(data)\n",
    "              data=[]\n",
    "            firsty=y\n",
    "        cv2.rectangle(img,(x, y),(x + w, y + h),(0, 255, 0), 2)\n",
    "        # cv2_imshow(img)\n",
    "    full_list.reverse()\n",
    "    print(full_list)\n",
    "\n",
    "    new_data=[]\n",
    "    new_row=[]\n",
    "    for i in full_list:\n",
    "      for j in i:\n",
    "        new_row.append(j[0])\n",
    "      new_data.append(new_row)\n",
    "      new_row=[]\n",
    "\n",
    "    print(\"-- new_data --\")\n",
    "    print(new_data)\n",
    "    print(\"-- new_data --\")\n",
    "\n",
    "    # Convert list of lists into a DataFrame\n",
    "    df = pd.DataFrame(new_data)\n",
    "    df = df.applymap(lambda x: '' if pd.isna(x) else x)\n",
    "    from tabulate import tabulate\n",
    "    table = tabulate(df, headers='firstrow', tablefmt='grid')\n",
    "\n",
    "    # Print DataFrame\n",
    "    print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edd75ebc-efbd-45fc-b573-10514e796ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['--', 112], ['no effect', 114], ['green color', 112], [' softens', 113], ['none', 113]], [['--', 112], ['softened', 114], ['no change', 112], ['no change', 113], ['white', 113]], [['--', 112], ['no effect', 114], ['red color', 112], ['softens', 113], ['none', 113]], [['--', 112], ['no effect', 114], ['green color', 112], [' softens', 113], ['none', 113]]]\n",
      "-- new_data --\n",
      "[['--', 'no effect', 'green color', ' softens', 'none'], ['--', 'softened', 'no change', 'no change', 'white'], ['--', 'no effect', 'red color', 'softens', 'none'], ['--', 'no effect', 'green color', ' softens', 'none']]\n",
      "-- new_data --\n",
      "+-----+------+-------------+---------------+------------+--------+\n",
      "|   0 | --   | no effect   | green color   |  softens   | none   |\n",
      "+=====+======+=============+===============+============+========+\n",
      "|   1 | --   | softened    | no change     | no change  | white  |\n",
      "+-----+------+-------------+---------------+------------+--------+\n",
      "|   2 | --   | no effect   | red color     | softens    | none   |\n",
      "+-----+------+-------------+---------------+------------+--------+\n",
      "|   3 | --   | no effect   | green color   | softens    | none   |\n",
      "+-----+------+-------------+---------------+------------+--------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37438/1673926649.py:79: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: '' if pd.isna(x) else x)\n"
     ]
    }
   ],
   "source": [
    "img_path = \"/home/ahsan/Downloads/table2.png\"\n",
    "table_detection(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6f1b51-602a-4100-8b78-091fdeca2f66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
